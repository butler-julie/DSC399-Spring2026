{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff0a714-c0af-4ec9-87e1-f460fdd2abb9",
   "metadata": {},
   "source": [
    "# Review of Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f132979-7886-40cf-9c0e-da6a61b17c4f",
   "metadata": {},
   "source": [
    "## Introduction and Termoinology\n",
    "\n",
    "* This week we will cover convolutional neural networks (CNNs)\n",
    "    * Image analysis, video analysis, object detection\n",
    "* Note that we will not be going through any mathematics this week as the mathematics of CNNs is quite complicated but there are many good resources (including your textbook) if you are interested\n",
    "    * A few suggestions:\n",
    "        * [Gentle Dive into Math Behind Convolutional Neural Networks](https://medium.com/data-science/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)\n",
    "        * [CNN Slides from the University of Houston](https://www.math.uh.edu/~dlabate/Lecture_6373_03.pdf)\n",
    "    * Note that while I do not expect you do know the mathematics behind the CNNs, you will need to know the dimension of the data after the final CNN layer in order to create the linear layers in PyTorch. You may use any resource avaliable to you (include the AIs) to calculate this if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7978924-6134-4f9e-82c9-893039846ec1",
   "metadata": {},
   "source": [
    "* Convolution refers to the mathematical combination of two functions to produce a third function\n",
    "    * It merges two sets of information\n",
    "* The convolution is performed on the input data with the use of a filter or kernel (these terms are used interchangeably) to then produce a feature map.\n",
    "    * Filters are matrices which are multiplied (element-wise) by the original data to produce a new value (reduces the dimensions, downsampling)\n",
    "* Pooling layers further downsample by aggregating the data. Max pooling is the most common form of pooling.\n",
    "\n",
    "![CNNs](https://cdn-media-1.freecodecamp.org/images/Htskzls1pGp98-X2mHmVy9tCj0cYXkiCrQ4t)\n",
    "\n",
    "[Image Source](https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2)\n",
    "\n",
    "![Pooling](https://miro.medium.com/v2/resize:fit:1400/1*vOxthD0FpBR6fJcpPxq6Hg.gif)\n",
    "[Image Source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2F%40Suraj_Yadav%2Fin-depth-knowledge-of-convolutional-neural-networks-b4bfff8145ab&psig=AOvVaw1hiVwrSrEA2eSW1DDEdkW_&ust=1760997780911000&source=images&cd=vfe&opi=89978449&ved=0CBUQjRxqFwoTCKC1jouisZADFQAAAAAdAAAAABAe)\n",
    "\n",
    "![CNNs](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv2-9x5-Conv2Conv2.png)\n",
    "[Image Source](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/)\n",
    "\n",
    "* CNNs use many identical copies of the same neurons \n",
    "    * This allows very large models to have a reasonable number of parameters\n",
    "\n",
    "Please see this series of articles for a in-depth review of CNNs:\n",
    "* [Conv Nets: A Modular Perspective](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/)\n",
    "* [Understanding Convolutions](https://colah.github.io/posts/2014-07-Understanding-Convolutions/)\n",
    "* [Groups & Group Convolutions](https://colah.github.io/posts/2014-12-Groups-Convolution/)\n",
    "* [Deconvolution and Checkerboard Artifacts](https://distill.pub/2016/deconv-checkerboard/)\n",
    "\n",
    "* **Note:** Chris Olah's entire blog is a great read, with one of his articles (on LSTMs) making it to the list of top 30 Machine Learning Papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e49570-ec91-4890-ab90-5038f2b27fd8",
   "metadata": {},
   "source": [
    "See the lecture notes from day 1 as well as homework for some examples and practice with basic CNNs.\n",
    "\n",
    "On Wednesday we will be looking into pre-trained CNNs. Some suggested pre-reading before then:\n",
    "* [CNN Transfer Learning](https://www.scaler.com/topics/tensorflow/transfer-learning-in-cnn)\n",
    "* [Pretrained Models in CNN: ImageNet, AlexNet, and the Rise of Transfer Learning](https://www.aryanupadhyay.com/post/pretrained-models-in-cnn-imagenet-alexnet-and-the-rise-of-transfer-learning?utm_source=chatgpt.com)\n",
    "* Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\n",
    "* [Inception (deep learning architecture)](https://en.wikipedia.org/wiki/Inception_(deep_learning_architecture))\n",
    "* [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "* [Residual neural network](https://en.wikipedia.org/wiki/Residual_neural_network)\n",
    "\n",
    "This also means that we will be learning _transfer learning_ on Wednesday. Last we we use a pre-trained LLM but did not do any additional training to it. This week we will start with a pre-trained model but continuing the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f08a05",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
