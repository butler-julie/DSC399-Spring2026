{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da458907",
   "metadata": {},
   "source": [
    "# Homework 1 Part 2: RAG\n",
    "\n",
    "## Conceptual \n",
    "\n",
    "Answer the below questions in complete sentences. If you use resources outside of the course notes and code, please provide a link or citation.\n",
    "1. Suppose you are building a small RAG system for a physics course using a database of lecture notes and textbook excerpts. Describe how the system would answer the student question: “What observational evidence supports the existence of dark matter?” Your explanation should include: how the system retrieves information, how it selects which passages to use, and how the LLM incorporates those passages into a final answer.\n",
    "2. Explain why a RAG system includes a retriever rather than relying solely on the language model’s pretrained knowledge.Also, and perhaps related, explain why RAG reduces hallucinations compared to a standalone LLM.\n",
    "3. Why do RAG pipelines break large documents (e.g., PDFs or textbooks) into smaller “chunks”?\n",
    "Describe one potential drawback of making chunks too small.\n",
    "4. Describe one reason a RAG system might retrieve irrelevant passages, even if the documents contain the answer.\n",
    "\n",
    "\n",
    "## Code Augmentation\n",
    "1. Create a new version of the retrieval code from the notes here. Replace the current PDF file with a new PDF of your choosing. Use either a long PDF (like a book or textbook) or concatenate several shorter PDF files together. If you need ideas, try [one of these free computer science textbooks](https://openstax.org/subjects/computer-science#Foundations%20of%20Computer%20Science). Test the retrieval capabilities of the code using several different queries, batch sizes, sentence per chunk sizes, embedding methods, etc. Report your results in a couple paragraphs in a markdown cell. Careful that your average tokens per chunk is less than the maximum of the embedding software (384 if you are using the version from the classnotes).\n",
    "2. Load a new model from Hugging Face. This can be a different model from the Google Gemma family or a new family of models. **Be careful that you are using a model that is an appropriate size for your computer.** \n",
    "3. Test the LLMs response to a few queries on your text and then compare them to the same queries using RAG. Write a couple paragraphs summarizing your findings and experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556a397",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
